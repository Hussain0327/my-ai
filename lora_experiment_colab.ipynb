{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# ValtricAI Research: LoRA Rank Impact on Financial Sentiment Analysis\n",
        "\n",
        "**Research Question:** How does LoRA rank affect small model performance on financial sentiment?\n",
        "\n",
        "**Hypothesis:** LoRA with ~1-2% parameters can match full fine-tuning accuracy.\n",
        "\n",
        "---\n",
        "\n",
        "## Experiments:\n",
        "1. **Full Fine-tuning** (baseline) - 100% parameters\n",
        "2. **LoRA Rank=4** - ~0.8% parameters\n",
        "3. **LoRA Rank=64** - ~13% parameters\n",
        "\n",
        "---\n",
        "\n",
        "**Before running:** Go to `Runtime > Change runtime type` and select **GPU (T4)**"
      ],
      "metadata": {
        "id": "header"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Setup & Installation"
      ],
      "metadata": {
        "id": "setup-header"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "install"
      },
      "outputs": [],
      "source": [
        "!pip install -q transformers datasets peft accelerate scikit-learn evaluate"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import time\n",
        "import json\n",
        "import warnings\n",
        "from dataclasses import dataclass, asdict\n",
        "from typing import Optional\n",
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "from datasets import load_dataset\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForSequenceClassification,\n",
        "    TrainingArguments,\n",
        "    Trainer,\n",
        "    EarlyStoppingCallback,\n",
        ")\n",
        "from peft import LoraConfig, get_peft_model, TaskType\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# Check GPU\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")"
      ],
      "metadata": {
        "id": "imports"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Configuration"
      ],
      "metadata": {
        "id": "config-header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Configuration\n",
        "MODEL_NAME = \"distilroberta-base\"\n",
        "MAX_LENGTH = 128\n",
        "BATCH_SIZE = 32  # Can use larger batch on GPU\n",
        "LEARNING_RATE = 2e-5\n",
        "NUM_EPOCHS = 3\n",
        "SEED = 42\n",
        "\n",
        "# Label mapping\n",
        "LABEL_MAP = {\"bearish\": 0, \"bullish\": 1, \"neutral\": 2}\n",
        "ID_TO_LABEL = {0: \"bearish\", 1: \"bullish\", 2: \"neutral\"}\n",
        "\n",
        "@dataclass\n",
        "class ExperimentResult:\n",
        "    \"\"\"Store results from each experiment run.\"\"\"\n",
        "    model: str\n",
        "    lora_rank: Optional[int]\n",
        "    params_updated_pct: float\n",
        "    accuracy: float\n",
        "    f1_score: float\n",
        "    training_time_seconds: float\n",
        "    training_outcome: str\n",
        "    error_message: Optional[str] = None"
      ],
      "metadata": {
        "id": "config"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Helper Functions"
      ],
      "metadata": {
        "id": "helpers-header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def set_seed(seed: int):\n",
        "    \"\"\"Set random seeds for reproducibility.\"\"\"\n",
        "    torch.manual_seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    \"\"\"Compute accuracy and F1 score.\"\"\"\n",
        "    predictions, labels = eval_pred\n",
        "    predictions = np.argmax(predictions, axis=1)\n",
        "    acc = accuracy_score(labels, predictions)\n",
        "    f1 = f1_score(labels, predictions, average=\"weighted\")\n",
        "    return {\"accuracy\": acc, \"f1\": f1}\n",
        "\n",
        "def count_parameters(model):\n",
        "    \"\"\"Count total and trainable parameters.\"\"\"\n",
        "    total = sum(p.numel() for p in model.parameters())\n",
        "    trainable = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "    return total, trainable"
      ],
      "metadata": {
        "id": "helpers"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Load Dataset"
      ],
      "metadata": {
        "id": "data-header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Loading tokenizer...\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "\n",
        "print(\"Loading dataset...\")\n",
        "dataset = load_dataset(\"zeroshot/twitter-financial-news-sentiment\")\n",
        "dataset = dataset[\"train\"].train_test_split(test_size=0.2, seed=SEED)\n",
        "\n",
        "def tokenize_function(examples):\n",
        "    return tokenizer(\n",
        "        examples[\"text\"],\n",
        "        padding=\"max_length\",\n",
        "        truncation=True,\n",
        "        max_length=MAX_LENGTH,\n",
        "    )\n",
        "\n",
        "tokenized_dataset = dataset.map(tokenize_function, batched=True)\n",
        "tokenized_dataset = tokenized_dataset.rename_column(\"label\", \"labels\")\n",
        "tokenized_dataset.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
        "\n",
        "print(f\"Train samples: {len(tokenized_dataset['train'])}\")\n",
        "print(f\"Test samples: {len(tokenized_dataset['test'])}\")"
      ],
      "metadata": {
        "id": "load-data"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Experiment 1: Full Fine-Tuning (Baseline)"
      ],
      "metadata": {
        "id": "exp1-header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"=\"*60)\n",
        "print(\"EXPERIMENT 1: Full Fine-Tuning (Baseline)\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "set_seed(SEED)\n",
        "start_time = time.time()\n",
        "\n",
        "# Load model\n",
        "model_full = AutoModelForSequenceClassification.from_pretrained(\n",
        "    MODEL_NAME,\n",
        "    num_labels=3,\n",
        "    id2label=ID_TO_LABEL,\n",
        "    label2id=LABEL_MAP,\n",
        ")\n",
        "\n",
        "total_params, trainable_params = count_parameters(model_full)\n",
        "print(f\"Total parameters: {total_params:,}\")\n",
        "print(f\"Trainable parameters: {trainable_params:,} (100%)\")\n",
        "\n",
        "# Training\n",
        "training_args_full = TrainingArguments(\n",
        "    output_dir=\"./results_full_ft\",\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    learning_rate=LEARNING_RATE,\n",
        "    per_device_train_batch_size=BATCH_SIZE,\n",
        "    per_device_eval_batch_size=BATCH_SIZE,\n",
        "    num_train_epochs=NUM_EPOCHS,\n",
        "    weight_decay=0.01,\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"accuracy\",\n",
        "    logging_steps=50,\n",
        "    seed=SEED,\n",
        "    report_to=\"none\",\n",
        "    fp16=torch.cuda.is_available(),  # Use mixed precision on GPU\n",
        ")\n",
        "\n",
        "trainer_full = Trainer(\n",
        "    model=model_full,\n",
        "    args=training_args_full,\n",
        "    train_dataset=tokenized_dataset[\"train\"],\n",
        "    eval_dataset=tokenized_dataset[\"test\"],\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics,\n",
        "    callbacks=[EarlyStoppingCallback(early_stopping_patience=2)],\n",
        ")\n",
        "\n",
        "print(\"\\nTraining...\")\n",
        "trainer_full.train()\n",
        "\n",
        "print(\"Evaluating...\")\n",
        "eval_full = trainer_full.evaluate()\n",
        "time_full = time.time() - start_time\n",
        "\n",
        "result_full = ExperimentResult(\n",
        "    model=\"distilroberta-base\",\n",
        "    lora_rank=None,\n",
        "    params_updated_pct=100.0,\n",
        "    accuracy=eval_full[\"eval_accuracy\"],\n",
        "    f1_score=eval_full[\"eval_f1\"],\n",
        "    training_time_seconds=time_full,\n",
        "    training_outcome=\"Success\",\n",
        ")\n",
        "\n",
        "print(f\"\\n{'='*40}\")\n",
        "print(f\"FULL FINE-TUNING RESULTS\")\n",
        "print(f\"{'='*40}\")\n",
        "print(f\"Accuracy: {result_full.accuracy:.4f}\")\n",
        "print(f\"F1 Score: {result_full.f1_score:.4f}\")\n",
        "print(f\"Training Time: {time_full:.1f}s\")\n",
        "\n",
        "# Cleanup\n",
        "del model_full, trainer_full\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "exp1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Experiment 2: LoRA Rank=4"
      ],
      "metadata": {
        "id": "exp2-header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"=\"*60)\n",
        "print(\"EXPERIMENT 2: LoRA Fine-Tuning (Rank = 4)\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "set_seed(SEED)\n",
        "start_time = time.time()\n",
        "\n",
        "# Load model\n",
        "model_lora4 = AutoModelForSequenceClassification.from_pretrained(\n",
        "    MODEL_NAME,\n",
        "    num_labels=3,\n",
        "    id2label=ID_TO_LABEL,\n",
        "    label2id=LABEL_MAP,\n",
        ")\n",
        "\n",
        "# Configure LoRA\n",
        "lora_config_4 = LoraConfig(\n",
        "    task_type=TaskType.SEQ_CLS,\n",
        "    r=4,\n",
        "    lora_alpha=8,\n",
        "    lora_dropout=0.1,\n",
        "    target_modules=[\"query\", \"value\"],\n",
        "    bias=\"none\",\n",
        ")\n",
        "\n",
        "model_lora4 = get_peft_model(model_lora4, lora_config_4)\n",
        "model_lora4.print_trainable_parameters()\n",
        "\n",
        "total_params, trainable_params = count_parameters(model_lora4)\n",
        "original_total = 82120707  # distilroberta-base\n",
        "params_pct_4 = (trainable_params / original_total) * 100\n",
        "\n",
        "# Training\n",
        "training_args_lora4 = TrainingArguments(\n",
        "    output_dir=\"./results_lora_r4\",\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    learning_rate=LEARNING_RATE * 5,  # Higher LR for LoRA\n",
        "    per_device_train_batch_size=BATCH_SIZE,\n",
        "    per_device_eval_batch_size=BATCH_SIZE,\n",
        "    num_train_epochs=NUM_EPOCHS,\n",
        "    weight_decay=0.01,\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"accuracy\",\n",
        "    logging_steps=50,\n",
        "    seed=SEED,\n",
        "    report_to=\"none\",\n",
        "    fp16=torch.cuda.is_available(),\n",
        ")\n",
        "\n",
        "trainer_lora4 = Trainer(\n",
        "    model=model_lora4,\n",
        "    args=training_args_lora4,\n",
        "    train_dataset=tokenized_dataset[\"train\"],\n",
        "    eval_dataset=tokenized_dataset[\"test\"],\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics,\n",
        "    callbacks=[EarlyStoppingCallback(early_stopping_patience=2)],\n",
        ")\n",
        "\n",
        "print(\"\\nTraining...\")\n",
        "trainer_lora4.train()\n",
        "\n",
        "print(\"Evaluating...\")\n",
        "eval_lora4 = trainer_lora4.evaluate()\n",
        "time_lora4 = time.time() - start_time\n",
        "\n",
        "result_lora4 = ExperimentResult(\n",
        "    model=\"distilroberta-base + LoRA\",\n",
        "    lora_rank=4,\n",
        "    params_updated_pct=round(params_pct_4, 2),\n",
        "    accuracy=eval_lora4[\"eval_accuracy\"],\n",
        "    f1_score=eval_lora4[\"eval_f1\"],\n",
        "    training_time_seconds=time_lora4,\n",
        "    training_outcome=\"Success\",\n",
        ")\n",
        "\n",
        "print(f\"\\n{'='*40}\")\n",
        "print(f\"LORA RANK=4 RESULTS\")\n",
        "print(f\"{'='*40}\")\n",
        "print(f\"Trainable Params: {params_pct_4:.2f}%\")\n",
        "print(f\"Accuracy: {result_lora4.accuracy:.4f}\")\n",
        "print(f\"F1 Score: {result_lora4.f1_score:.4f}\")\n",
        "print(f\"Training Time: {time_lora4:.1f}s\")\n",
        "\n",
        "# Cleanup\n",
        "del model_lora4, trainer_lora4\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "exp2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7. Experiment 3: LoRA Rank=64"
      ],
      "metadata": {
        "id": "exp3-header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"=\"*60)\n",
        "print(\"EXPERIMENT 3: LoRA Fine-Tuning (Rank = 64)\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "set_seed(SEED)\n",
        "start_time = time.time()\n",
        "\n",
        "# Load model\n",
        "model_lora64 = AutoModelForSequenceClassification.from_pretrained(\n",
        "    MODEL_NAME,\n",
        "    num_labels=3,\n",
        "    id2label=ID_TO_LABEL,\n",
        "    label2id=LABEL_MAP,\n",
        ")\n",
        "\n",
        "# Configure LoRA\n",
        "lora_config_64 = LoraConfig(\n",
        "    task_type=TaskType.SEQ_CLS,\n",
        "    r=64,\n",
        "    lora_alpha=128,\n",
        "    lora_dropout=0.1,\n",
        "    target_modules=[\"query\", \"value\"],\n",
        "    bias=\"none\",\n",
        ")\n",
        "\n",
        "model_lora64 = get_peft_model(model_lora64, lora_config_64)\n",
        "model_lora64.print_trainable_parameters()\n",
        "\n",
        "total_params, trainable_params = count_parameters(model_lora64)\n",
        "original_total = 82120707\n",
        "params_pct_64 = (trainable_params / original_total) * 100\n",
        "\n",
        "# Training\n",
        "training_args_lora64 = TrainingArguments(\n",
        "    output_dir=\"./results_lora_r64\",\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    learning_rate=LEARNING_RATE * 5,\n",
        "    per_device_train_batch_size=BATCH_SIZE,\n",
        "    per_device_eval_batch_size=BATCH_SIZE,\n",
        "    num_train_epochs=NUM_EPOCHS,\n",
        "    weight_decay=0.01,\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"accuracy\",\n",
        "    logging_steps=50,\n",
        "    seed=SEED,\n",
        "    report_to=\"none\",\n",
        "    fp16=torch.cuda.is_available(),\n",
        ")\n",
        "\n",
        "trainer_lora64 = Trainer(\n",
        "    model=model_lora64,\n",
        "    args=training_args_lora64,\n",
        "    train_dataset=tokenized_dataset[\"train\"],\n",
        "    eval_dataset=tokenized_dataset[\"test\"],\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics,\n",
        "    callbacks=[EarlyStoppingCallback(early_stopping_patience=2)],\n",
        ")\n",
        "\n",
        "print(\"\\nTraining...\")\n",
        "trainer_lora64.train()\n",
        "\n",
        "print(\"Evaluating...\")\n",
        "eval_lora64 = trainer_lora64.evaluate()\n",
        "time_lora64 = time.time() - start_time\n",
        "\n",
        "result_lora64 = ExperimentResult(\n",
        "    model=\"distilroberta-base + LoRA\",\n",
        "    lora_rank=64,\n",
        "    params_updated_pct=round(params_pct_64, 2),\n",
        "    accuracy=eval_lora64[\"eval_accuracy\"],\n",
        "    f1_score=eval_lora64[\"eval_f1\"],\n",
        "    training_time_seconds=time_lora64,\n",
        "    training_outcome=\"Success\",\n",
        ")\n",
        "\n",
        "print(f\"\\n{'='*40}\")\n",
        "print(f\"LORA RANK=64 RESULTS\")\n",
        "print(f\"{'='*40}\")\n",
        "print(f\"Trainable Params: {params_pct_64:.2f}%\")\n",
        "print(f\"Accuracy: {result_lora64.accuracy:.4f}\")\n",
        "print(f\"F1 Score: {result_lora64.f1_score:.4f}\")\n",
        "print(f\"Training Time: {time_lora64:.1f}s\")\n",
        "\n",
        "# Cleanup\n",
        "del model_lora64, trainer_lora64\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "exp3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8. Results Summary"
      ],
      "metadata": {
        "id": "results-header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results = [result_full, result_lora4, result_lora64]\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"VALTRICAI RESEARCH: LORA RANK IMPACT STUDY - FINAL RESULTS\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "print(\"\\n| Configuration | % Params | Accuracy | F1 Score | Time (s) |\")\n",
        "print(\"|---------------|----------|----------|----------|----------|\")\n",
        "\n",
        "for r in results:\n",
        "    config = \"Full Fine-Tuning\" if r.lora_rank is None else f\"LoRA (r={r.lora_rank})\"\n",
        "    print(f\"| {config:<13} | {r.params_updated_pct:>6.2f}% | {r.accuracy:>8.4f} | {r.f1_score:>8.4f} | {r.training_time_seconds:>8.1f} |\")\n",
        "\n",
        "# Analysis\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"EFFICIENCY ANALYSIS\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "baseline_acc = result_full.accuracy\n",
        "baseline_time = result_full.training_time_seconds\n",
        "\n",
        "for r in [result_lora4, result_lora64]:\n",
        "    acc_diff = (baseline_acc - r.accuracy) * 100\n",
        "    time_savings = ((baseline_time - r.training_time_seconds) / baseline_time) * 100\n",
        "    param_savings = 100 - r.params_updated_pct\n",
        "    \n",
        "    print(f\"\\nLoRA Rank={r.lora_rank}:\")\n",
        "    print(f\"  - Accuracy difference: {acc_diff:+.2f}% points\")\n",
        "    print(f\"  - Training time savings: {time_savings:.1f}%\")\n",
        "    print(f\"  - Parameter reduction: {param_savings:.1f}%\")"
      ],
      "metadata": {
        "id": "results"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 9. Save Results"
      ],
      "metadata": {
        "id": "save-header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save to JSON\n",
        "with open(\"experiment_results.json\", \"w\") as f:\n",
        "    json.dump([asdict(r) for r in results], f, indent=2)\n",
        "\n",
        "print(\"Results saved to experiment_results.json\")\n",
        "\n",
        "# Display JSON\n",
        "print(\"\\n\" + json.dumps([asdict(r) for r in results], indent=2))"
      ],
      "metadata": {
        "id": "save"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 10. Generate LaTeX Table"
      ],
      "metadata": {
        "id": "latex-header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "latex_table = r\"\"\"\n",
        "\\begin{table}[h]\n",
        "\\centering\n",
        "\\caption{LoRA Rank Impact on Financial Sentiment Classification}\n",
        "\\label{tab:results}\n",
        "\\begin{tabular}{@{}lcccc@{}}\n",
        "\\toprule\n",
        "\\textbf{Configuration} & \\textbf{Params (\\%)} & \\textbf{Accuracy} & \\textbf{F1} & \\textbf{Time (s)} \\\\\n",
        "\\midrule\n",
        "\"\"\"\n",
        "\n",
        "for r in results:\n",
        "    config = \"Full Fine-Tuning\" if r.lora_rank is None else f\"LoRA ($r={r.lora_rank}$)\"\n",
        "    latex_table += f\"{config} & {r.params_updated_pct:.2f} & {r.accuracy:.4f} & {r.f1_score:.4f} & {r.training_time_seconds:.1f} \\\\\\\\\\n\"\n",
        "\n",
        "latex_table += r\"\"\"\\bottomrule\n",
        "\\end{tabular}\n",
        "\\end{table}\n",
        "\"\"\"\n",
        "\n",
        "print(\"LaTeX Table:\")\n",
        "print(latex_table)\n",
        "\n",
        "with open(\"results_table.tex\", \"w\") as f:\n",
        "    f.write(latex_table)\n",
        "print(\"\\nSaved to results_table.tex\")"
      ],
      "metadata": {
        "id": "latex"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "## Key Findings\n",
        "\n",
        "After running all experiments, analyze:\n",
        "\n",
        "1. **Can LoRA match full fine-tuning?**\n",
        "   - Compare accuracy difference between methods\n",
        "   \n",
        "2. **What's the optimal rank?**\n",
        "   - r=4 vs r=64 tradeoffs\n",
        "   \n",
        "3. **Compute savings?**\n",
        "   - Training time reduction\n",
        "   - Parameter efficiency gains\n",
        "\n",
        "---\n",
        "\n",
        "*ValtricAI Research - December 2025*"
      ],
      "metadata": {
        "id": "conclusion"
      }
    }
  ]
}
